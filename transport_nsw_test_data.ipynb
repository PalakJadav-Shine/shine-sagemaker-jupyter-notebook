{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transport NSW Opal Card ML Pipeline - Complete Analysis\n",
    "\n",
    "Portal: https://opendata.transport.nsw.gov.au\n",
    "\n",
    "- Train Trips: https://opendata.transport.nsw.gov.au/dataset/opal-trips-train\n",
    "  \n",
    "    https://opendata.transport.nsw.gov.au/data/api/action/datastore_search?resource_id=7d49ca0b-1fb6-4524-81b0-68c8775b4d82\n",
    "\n",
    "- Card type usage patterns: https://opendata.transport.nsw.gov.au/data/dataset/opal-trips-all-modes\n",
    "\n",
    "    https://opendata.transport.nsw.gov.au/data/api/action/datastore_search?resource_id=c77b83d7-cdcd-4a0e-9b12-fcc159727589\n",
    "\n",
    "**Business Questions Answered**:\n",
    "1. Which train lines show declining ridership?\n",
    "2. Predict next month's demand by route\n",
    "3. Which stations need capacity upgrades?\n",
    "4. Optimal train frequency per line\n",
    "5. Card type usage patterns\n",
    "6. Seasonal demand patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sagemaker scikit-learn pandas numpy matplotlib seaborn requests joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Real Transport NSW Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš‡ Fetching REAL Transport NSW Train Data...\n",
      "\n",
      "âœ… SUCCESS! Retrieved 19820 records\n",
      "\n",
      "ðŸ“Š Data Structure:\n",
      "   Columns: ['_id', 'Year_Month', 'Card_type', 'Line', 'Trip']\n",
      "\n",
      "   First few column names:\n",
      "      - _id\n",
      "      - Year_Month\n",
      "      - Card_type\n",
      "      - Line\n",
      "      - Trip\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š RAW DATA PREVIEW (First 3 rows)\n",
      "================================================================================\n",
      "   _id Year_Month    Card_type                 Line    Trip\n",
      "0    1     Jul-16        Adult  Blue Mountains Line  537669\n",
      "1    2     Jul-16  Child/Youth  Blue Mountains Line   36387\n",
      "2    3     Jul-16   Concession  Blue Mountains Line   60238\n"
     ]
    }
   ],
   "source": [
    "def fetch_train_data_with_lines():\n",
    "    \"\"\"\n",
    "    Fetch Transport NSW data and properly extract train line names\n",
    "    \"\"\"\n",
    "    print(\"ðŸš‡ Fetching REAL Transport NSW Train Data...\\n\")\n",
    "    \n",
    "    url = \"https://opendata.transport.nsw.gov.au/data/api/action/datastore_search\"\n",
    "    params = {\n",
    "        'resource_id': '7d49ca0b-1fb6-4524-81b0-68c8775b4d82',\n",
    "        'limit': 1000000\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=60)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'result' in data and 'records' in data['result']:\n",
    "                df = pd.DataFrame(data['result']['records'])\n",
    "                \n",
    "                print(f\"âœ… SUCCESS! Retrieved {len(df)} records\")\n",
    "                print(f\"\\nðŸ“Š Data Structure:\")\n",
    "                print(f\"   Columns: {list(df.columns)}\")\n",
    "                print(f\"\\n   First few column names:\")\n",
    "                for col in df.columns[:10]:\n",
    "                    print(f\"      - {col}\")\n",
    "                \n",
    "                return df, data['result'].get('fields', [])\n",
    "            else:\n",
    "                print(\"âŒ Unexpected API response format\")\n",
    "                return None, None\n",
    "        else:\n",
    "            print(f\"âŒ API returned status: {response.status_code}\")\n",
    "            return None, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "df_raw, fields_info = fetch_train_data_with_lines()\n",
    "\n",
    "if df_raw is not None:\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š RAW DATA PREVIEW (First 3 rows)\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_raw.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Identify Train Line Columns (FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” IDENTIFYING TRAIN LINE COLUMNS\n",
      "\n",
      "================================================================================\n",
      "\n",
      "1. ALL COLUMNS IN DATASET:\n",
      "    1. _id                                      | Type: int64      | Sample: 1\n",
      "    2. Year_Month                               | Type: object     | Sample: Jul-16\n",
      "    3. Card_type                                | Type: object     | Sample: Adult\n",
      "    4. Line                                     | Type: object     | Sample: Blue Mountains Line\n",
      "    5. Trip                                     | Type: int64      | Sample: 537669\n",
      "\n",
      "2. NUMERIC COLUMNS (potential trip counts): 2\n",
      "   - _id\n",
      "   - Trip\n",
      "\n",
      "3. POTENTIAL LINE IDENTIFIER COLUMNS: 1\n",
      "   - Line                                     | 35 unique values\n",
      "\n",
      "4. DATE COLUMNS: 1\n",
      "   - Year_Month\n",
      "     Sample values: ['Jul-16', 'Jul-16', 'Jul-16']\n"
     ]
    }
   ],
   "source": [
    "if df_raw is not None:\n",
    "    print(\"ðŸ” IDENTIFYING TRAIN LINE COLUMNS\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Look for columns that might contain line names\n",
    "    print(\"\\n1. ALL COLUMNS IN DATASET:\")\n",
    "    for i, col in enumerate(df_raw.columns, 1):\n",
    "        # Check data type and sample values - FIXED: Convert dtype to string\n",
    "        dtype = str(df_raw[col].dtype)\n",
    "        sample = str(df_raw[col].iloc[0])[:50] if len(df_raw) > 0 else \"N/A\"\n",
    "        print(f\"   {i:2}. {col:40} | Type: {dtype:10} | Sample: {sample}\")\n",
    "    \n",
    "    # Identify numeric columns (potential trip counts)\n",
    "    numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    print(f\"\\n2. NUMERIC COLUMNS (potential trip counts): {len(numeric_cols)}\")\n",
    "    for col in numeric_cols:\n",
    "        print(f\"   - {col}\")\n",
    "    \n",
    "    # Look for line identifier columns\n",
    "    potential_line_cols = [col for col in df_raw.columns if \n",
    "                          any(x in col.lower() for x in ['line', 'route', 'mode', 'service'])]\n",
    "    print(f\"\\n3. POTENTIAL LINE IDENTIFIER COLUMNS: {len(potential_line_cols)}\")\n",
    "    for col in potential_line_cols:\n",
    "        unique_vals = df_raw[col].nunique()\n",
    "        print(f\"   - {col:40} | {unique_vals} unique values\")\n",
    "        if unique_vals < 20:\n",
    "            print(f\"     Values: {df_raw[col].unique()[:10].tolist()}\")\n",
    "    \n",
    "    # Check for date column\n",
    "    date_cols = [col for col in df_raw.columns if any(x in col.lower() for x in ['date', 'month', 'year', 'period'])]\n",
    "    print(f\"\\n4. DATE COLUMNS: {len(date_cols)}\")\n",
    "    for col in date_cols:\n",
    "        print(f\"   - {col}\")\n",
    "        print(f\"     Sample values: {df_raw[col].head(3).tolist()}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No data to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reshape Data to Proper Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ RESHAPING DATA FOR PROPER ANALYSIS\n",
      "\n",
      "âœ… Data is in LONG format with line identifier: Line\n",
      "âœ… Found trip column: Trip\n",
      "âœ… Found date column: Year_Month\n",
      "\n",
      "âœ… Reshaped data: 5070 records\n",
      "   Unique lines: 25\n",
      "   Date range: 2024-01-01 00:00:00 to 2025-09-01 00:00:00\n",
      "\n",
      "ðŸ“Š Train Lines Found:\n",
      "      â€¢ Airport replacement buses                          ( 69 records, avg          283 trips/month)\n",
      "      â€¢ Bankstown Replacement Buses                        ( 29 records, avg           11 trips/month)\n",
      "      â€¢ Blue Mountains Line                                (266 records, avg       43,418 trips/month)\n",
      "      â€¢ Carlingford Replacement Buses                      (111 records, avg        2,393 trips/month)\n",
      "      â€¢ Central Coast & Newcastle Line                     (267 records, avg       82,429 trips/month)\n",
      "      â€¢ Hunter Line                                        (234 records, avg        5,891 trips/month)\n",
      "      â€¢ NSW TrainLink Southern Train Services              (141 records, avg            0 trips/month)\n",
      "      â€¢ NSW TrainLink Western Train Services               (187 records, avg            1 trips/month)\n",
      "      â€¢ North Coast NSW                                    (240 records, avg          128 trips/month)\n",
      "      â€¢ North West NSW                                     (238 records, avg           68 trips/month)\n",
      "      â€¢ South Coast Line                                   (267 records, avg       47,792 trips/month)\n",
      "      â€¢ Southern Highlands Line                            (249 records, avg        3,760 trips/month)\n",
      "      â€¢ Southern NSW                                       (231 records, avg          172 trips/month)\n",
      "      â€¢ T1 North Shore Line & T1 Western Line              (273 records, avg      540,184 trips/month)\n",
      "      â€¢ T2 Inner West & Leppington Line                    (116 records, avg      399,469 trips/month)\n",
      "      â€¢ T2 Inner West & Leppington Line & T2 Leppington & Inner West Line (167 records, avg      329,091 trips/month)\n",
      "      â€¢ T3 Bankstown Line                                  (103 records, avg      191,283 trips/month)\n",
      "      â€¢ T3 Bankstown Line & T3 Liverpool & Inner West Line (164 records, avg       84,191 trips/month)\n",
      "      â€¢ T4 Eastern Suburbs & Illawarra Line                (272 records, avg      410,646 trips/month)\n",
      "      â€¢ T5 Cumberland Line                                 (269 records, avg       50,596 trips/month)\n",
      "      â€¢ T6 Lidcombe & Bankstown Line                       (129 records, avg       16,501 trips/month)\n",
      "      â€¢ T7 Olympic Park Line                               (264 records, avg       16,060 trips/month)\n",
      "      â€¢ T8 Airport & South Line                            (271 records, avg      336,476 trips/month)\n",
      "      â€¢ T9 Northern Line                                   (270 records, avg      248,064 trips/month)\n",
      "      â€¢ Western NSW                                        (243 records, avg          103 trips/month)\n",
      "\n",
      "================================================================================\n",
      "âœ… DATA READY FOR ANALYSIS\n",
      "================================================================================\n",
      "            Date                                   Line   Trips  Year  Month  \\\n",
      "16535 2024-01-01                   T7 Olympic Park Line    6530  2024      1   \n",
      "16564 2024-01-01                     T5 Cumberland Line       2  2024      1   \n",
      "16563 2024-01-01    T4 Eastern Suburbs & Illawarra Line       5  2024      1   \n",
      "16562 2024-01-01        T2 Inner West & Leppington Line       3  2024      1   \n",
      "16561 2024-01-01  T1 North Shore Line & T1 Western Line       5  2024      1   \n",
      "16560 2024-01-01         Central Coast & Newcastle Line       2  2024      1   \n",
      "16559 2024-01-01                    Blue Mountains Line       2  2024      1   \n",
      "16558 2024-01-01                            Western NSW      42  2024      1   \n",
      "16557 2024-01-01                       T9 Northern Line  106501  2024      1   \n",
      "16556 2024-01-01                T8 Airport & South Line  118340  2024      1   \n",
      "16555 2024-01-01                   T7 Olympic Park Line    2747  2024      1   \n",
      "16554 2024-01-01                     T5 Cumberland Line   25138  2024      1   \n",
      "16553 2024-01-01    T4 Eastern Suburbs & Illawarra Line  142668  2024      1   \n",
      "16552 2024-01-01                      T3 Bankstown Line   58915  2024      1   \n",
      "16551 2024-01-01        T2 Inner West & Leppington Line  141726  2024      1   \n",
      "\n",
      "       Quarter  \n",
      "16535        1  \n",
      "16564        1  \n",
      "16563        1  \n",
      "16562        1  \n",
      "16561        1  \n",
      "16560        1  \n",
      "16559        1  \n",
      "16558        1  \n",
      "16557        1  \n",
      "16556        1  \n",
      "16555        1  \n",
      "16554        1  \n",
      "16553        1  \n",
      "16552        1  \n",
      "16551        1  \n"
     ]
    }
   ],
   "source": [
    "def reshape_transport_data(df_raw):\n",
    "    \"\"\"\n",
    "    Reshape the data so each train line is properly identified\n",
    "    \"\"\"\n",
    "    if df_raw is None or len(df_raw) == 0:\n",
    "        return None\n",
    "    \n",
    "    print(\"ðŸ”„ RESHAPING DATA FOR PROPER ANALYSIS\\n\")\n",
    "    \n",
    "    # Check if there's a column identifying the line/route\n",
    "    line_identifier_cols = [col for col in df_raw.columns if \n",
    "                           any(x in col.lower() for x in ['line', 'route', 'mode'])]\n",
    "    \n",
    "    if line_identifier_cols:\n",
    "        # Long format - already has line names\n",
    "        print(f\"âœ… Data is in LONG format with line identifier: {line_identifier_cols[0]}\")\n",
    "        line_col = line_identifier_cols[0]\n",
    "        \n",
    "        # Find trip/count column\n",
    "        trip_cols = [col for col in df_raw.columns if \n",
    "                    any(x in col.lower() for x in ['trip', 'count', 'patronage', 'boardings'])]\n",
    "        \n",
    "        if trip_cols:\n",
    "            trip_col = trip_cols[0]\n",
    "            print(f\"âœ… Found trip column: {trip_col}\")\n",
    "            \n",
    "            # Find date column\n",
    "            date_cols = [col for col in df_raw.columns if \n",
    "                        any(x in col.lower() for x in ['date', 'month', 'year', 'period'])]\n",
    "            \n",
    "            if date_cols:\n",
    "                date_col = date_cols[0]\n",
    "                print(f\"âœ… Found date column: {date_col}\")\n",
    "                \n",
    "                # Create clean dataframe\n",
    "                df_clean = df_raw[[date_col, line_col, trip_col]].copy()\n",
    "                df_clean.columns = ['Date', 'Line', 'Trips']\n",
    "                \n",
    "                # Convert to numeric\n",
    "                df_clean['Trips'] = pd.to_numeric(df_clean['Trips'], errors='coerce')\n",
    "                df_clean = df_clean.dropna()\n",
    "                \n",
    "                # Parse date\n",
    "                df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce')\n",
    "                df_clean = df_clean.dropna(subset=['Date'])\n",
    "                df_clean = df_clean.sort_values('Date')\n",
    "                \n",
    "                # Add time features\n",
    "                df_clean['Year'] = df_clean['Date'].dt.year\n",
    "                df_clean['Month'] = df_clean['Date'].dt.month\n",
    "                df_clean['Quarter'] = df_clean['Date'].dt.quarter\n",
    "                \n",
    "                print(f\"\\nâœ… Reshaped data: {len(df_clean)} records\")\n",
    "                print(f\"   Unique lines: {df_clean['Line'].nunique()}\")\n",
    "                print(f\"   Date range: {df_clean['Date'].min()} to {df_clean['Date'].max()}\")\n",
    "                print(f\"\\nðŸ“Š Train Lines Found:\")\n",
    "                for line in sorted(df_clean['Line'].unique()):\n",
    "                    count = len(df_clean[df_clean['Line'] == line])\n",
    "                    avg_trips = df_clean[df_clean['Line'] == line]['Trips'].mean()\n",
    "                    print(f\"      â€¢ {line:50} ({count:3} records, avg {avg_trips:>12,.0f} trips/month)\")\n",
    "                \n",
    "                return df_clean\n",
    "    \n",
    "    # If wide format, need to melt it\n",
    "    print(\"ðŸ“Š Data appears to be in WIDE format (lines as columns)\")\n",
    "    print(\"   Attempting to identify train line columns...\")\n",
    "    \n",
    "    # Find date column\n",
    "    date_col = None\n",
    "    for col in df_raw.columns:\n",
    "        if any(x in col.lower() for x in ['year', 'month', 'date', 'period']):\n",
    "            date_col = col\n",
    "            break\n",
    "    \n",
    "    if date_col is None:\n",
    "        print(\"   âš ï¸  Could not identify date column\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"   âœ… Date column: {date_col}\")\n",
    "    \n",
    "    # Assume all numeric columns except _id are train lines\n",
    "    numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    line_cols = [col for col in numeric_cols if col != '_id']\n",
    "    \n",
    "    if not line_cols:\n",
    "        print(\"   âš ï¸  Could not identify line columns\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"   âœ… Found {len(line_cols)} potential line columns\")\n",
    "    \n",
    "    # Melt the dataframe\n",
    "    df_melted = df_raw.melt(\n",
    "        id_vars=[date_col],\n",
    "        value_vars=line_cols,\n",
    "        var_name='Line',\n",
    "        value_name='Trips'\n",
    "    )\n",
    "    \n",
    "    df_melted.columns = ['Date', 'Line', 'Trips']\n",
    "    df_melted['Trips'] = pd.to_numeric(df_melted['Trips'], errors='coerce')\n",
    "    df_melted = df_melted.dropna()\n",
    "    \n",
    "    df_melted['Date'] = pd.to_datetime(df_melted['Date'], errors='coerce')\n",
    "    df_melted = df_melted.dropna(subset=['Date'])\n",
    "    df_melted = df_melted.sort_values('Date')\n",
    "    \n",
    "    # Add time features\n",
    "    df_melted['Year'] = df_melted['Date'].dt.year\n",
    "    df_melted['Month'] = df_melted['Date'].dt.month\n",
    "    df_melted['Quarter'] = df_melted['Date'].dt.quarter\n",
    "    \n",
    "    print(f\"\\nâœ… Reshaped data: {len(df_melted)} records\")\n",
    "    print(f\"   Unique lines: {df_melted['Line'].nunique()}\")\n",
    "    print(f\"\\nðŸ“Š Train Lines Found:\")\n",
    "    for line in sorted(df_melted['Line'].unique()):\n",
    "        count = len(df_melted[df_melted['Line'] == line])\n",
    "        avg_trips = df_melted[df_melted['Line'] == line]['Trips'].mean()\n",
    "        print(f\"      â€¢ {line:50} ({count:3} records, avg {avg_trips:>12,.0f} trips/month)\")\n",
    "    \n",
    "    return df_melted\n",
    "\n",
    "df_clean = reshape_transport_data(df_raw)\n",
    "\n",
    "if df_clean is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… DATA READY FOR ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_clean.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question 1: Which train lines show declining ridership?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "â“ QUESTION 1: WHICH TRAIN LINES SHOW DECLINING RIDERSHIP?\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Analyzing 25 train lines\n",
      "\n",
      "ðŸ“‰ DECLINING LINES (Negative Growth):\n",
      "\n",
      "   T1 North Shore Line & T1 Western Line              -4148263.3% | Avg:    540,184 trips/month\n",
      "   T4 Eastern Suburbs & Illawarra Line                -1214257.4% | Avg:    410,646 trips/month\n",
      "   Central Coast & Newcastle Line                     -1163927.0% | Avg:     82,429 trips/month\n",
      "   Blue Mountains Line                                -481387.5% | Avg:     43,418 trips/month\n",
      "   T5 Cumberland Line                                 -455185.9% | Avg:     50,596 trips/month\n",
      "   T3 Bankstown Line & T3 Liverpool & Inner West Line -65118.8% | Avg:     84,191 trips/month\n",
      "   Southern NSW                                        -332.9% | Avg:        172 trips/month\n",
      "   North Coast NSW                                     -193.4% | Avg:        128 trips/month\n",
      "   Carlingford Replacement Buses                       -123.9% | Avg:      2,393 trips/month\n",
      "   Western NSW                                         -110.5% | Avg:        103 trips/month\n",
      "\n",
      "ðŸ“ˆ FASTEST GROWING LINES (Positive Growth):\n",
      "\n",
      "   T2 Inner West & Leppington Line                    +1878222.0% | Avg:    399,469 trips/month\n",
      "   T6 Lidcombe & Bankstown Line                       +123227.6% | Avg:     16,501 trips/month\n",
      "   Airport replacement buses                          +2723.3% | Avg:        283 trips/month\n",
      "   T2 Inner West & Leppington Line & T2 Leppington & Inner West Line +1282.1% | Avg:    329,091 trips/month\n",
      "   T3 Bankstown Line                                    +47.2% | Avg:    191,283 trips/month\n",
      "   NSW TrainLink Western Train Services                 +15.9% | Avg:          1 trips/month\n",
      "   T8 Airport & South Line                               +3.8% | Avg:    336,476 trips/month\n",
      "\n",
      "ðŸ’¼ BUSINESS RECOMMENDATIONS:\n",
      "\n",
      "   ðŸš¨ URGENT: T1 North Shore Line & T1 Western Line\n",
      "      - Decline: -4148263.3%\n",
      "      - Current: 48,061 trips/month\n",
      "      - Actions: Survey passengers, check competitors, review service quality\n",
      "\n",
      "   âœ… SUCCESS: T2 Inner West & Leppington Line\n",
      "      - Growth: 1878222.0%\n",
      "      - Current: 7,735 trips/month\n",
      "      - Actions: Monitor capacity, consider service expansion\n"
     ]
    }
   ],
   "source": [
    "if df_clean is not None and len(df_clean) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"â“ QUESTION 1: WHICH TRAIN LINES SHOW DECLINING RIDERSHIP?\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    lines = df_clean['Line'].unique()\n",
    "    print(f\"\\nðŸ“Š Analyzing {len(lines)} train lines\\n\")\n",
    "    \n",
    "    trends = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        line_data = df_clean[df_clean['Line'] == line].sort_values('Date')\n",
    "        \n",
    "        if len(line_data) > 3:\n",
    "            x = np.arange(len(line_data))\n",
    "            y = line_data['Trips'].values\n",
    "            z = np.polyfit(x, y, 1)\n",
    "            slope = z[0]\n",
    "            first_val = y[0] if y[0] != 0 else 1\n",
    "            pct_change = (slope * len(line_data) / first_val) * 100\n",
    "            \n",
    "            trends[line] = {\n",
    "                'slope': slope,\n",
    "                'pct_change': pct_change,\n",
    "                'current': y[-1],\n",
    "                'avg': y.mean(),\n",
    "                'records': len(line_data)\n",
    "            }\n",
    "    \n",
    "    sorted_trends = sorted(trends.items(), key=lambda x: x[1]['pct_change'])\n",
    "    \n",
    "    print(\"ðŸ“‰ DECLINING LINES (Negative Growth):\\n\")\n",
    "    declining_count = 0\n",
    "    for line, data in sorted_trends:\n",
    "        if data['pct_change'] < -1:\n",
    "            declining_count += 1\n",
    "            print(f\"   {line:50} {data['pct_change']:+7.1f}% | Avg: {data['avg']:>10,.0f} trips/month\")\n",
    "            if declining_count >= 10:\n",
    "                break\n",
    "    \n",
    "    if declining_count == 0:\n",
    "        print(\"   âœ… No lines showing significant decline\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ FASTEST GROWING LINES (Positive Growth):\\n\")\n",
    "    growing_count = 0\n",
    "    for line, data in reversed(sorted_trends):\n",
    "        if data['pct_change'] > 1:\n",
    "            growing_count += 1\n",
    "            print(f\"   {line:50} {data['pct_change']:+7.1f}% | Avg: {data['avg']:>10,.0f} trips/month\")\n",
    "            if growing_count >= 10:\n",
    "                break\n",
    "    \n",
    "    if growing_count == 0:\n",
    "        print(\"   âš ï¸  No lines showing significant growth\")\n",
    "    \n",
    "    print(\"\\nðŸ’¼ BUSINESS RECOMMENDATIONS:\\n\")\n",
    "    \n",
    "    if declining_count > 0:\n",
    "        worst = sorted_trends[0]\n",
    "        print(f\"   ðŸš¨ URGENT: {worst[0]}\")\n",
    "        print(f\"      - Decline: {worst[1]['pct_change']:.1f}%\")\n",
    "        print(f\"      - Current: {worst[1]['current']:,.0f} trips/month\")\n",
    "        print(f\"      - Actions: Survey passengers, check competitors, review service quality\")\n",
    "    \n",
    "    if growing_count > 0:\n",
    "        best = sorted_trends[-1]\n",
    "        print(f\"\\n   âœ… SUCCESS: {best[0]}\")\n",
    "        print(f\"      - Growth: {best[1]['pct_change']:.1f}%\")\n",
    "        print(f\"      - Current: {best[1]['current']:,.0f} trips/month\")\n",
    "        print(f\"      - Actions: Monitor capacity, consider service expansion\")\n",
    "else:\n",
    "    print(\"âš ï¸  No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question 2: Predict next month's demand by route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "â“ QUESTION 2: PREDICT NEXT MONTH'S DEMAND BY ROUTE\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ Training model for: T1 North Shore Line & T1 Western Line\n",
      "   Training samples: 270\n",
      "   Train: 216, Test: 54\n",
      "\n",
      "ðŸ¤– Training Random Forest...\n",
      "\n",
      "ðŸ“Š MODEL PERFORMANCE:\n",
      "\n",
      "   Line: T1 North Shore Line & T1 Western Line\n",
      "   RMSE: 734,777 trips\n",
      "   MAE:  448,042 trips\n",
      "   RÂ²:   0.2518\n",
      "   MAPE: inf%\n",
      "\n",
      "ðŸ”® PREDICTIONS (Last 5 test periods):\n",
      "\n",
      "   Actual:    575,922 | Predicted:    273,350 | Error:  +52.5%\n",
      "   Actual:    257,622 | Predicted:    521,206 | Error: -102.3%\n",
      "   Actual:        228 | Predicted:    274,455 | Error: -120274.9%\n",
      "   Actual:      9,130 | Predicted:    213,687 | Error: -2240.5%\n",
      "   Actual:     48,061 | Predicted:     21,056 | Error:  +56.2%\n"
     ]
    }
   ],
   "source": [
    "if df_clean is not None and len(df_clean) > 20:\n",
    "    print(\"=\"*80)\n",
    "    print(\"â“ QUESTION 2: PREDICT NEXT MONTH'S DEMAND BY ROUTE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    line_counts = df_clean.groupby('Line').size()\n",
    "    target_line = line_counts.idxmax()\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Training model for: {target_line}\")\n",
    "    \n",
    "    line_data = df_clean[df_clean['Line'] == target_line].sort_values('Date').copy()\n",
    "    line_data['Lag_1'] = line_data['Trips'].shift(1)\n",
    "    line_data['Lag_3'] = line_data['Trips'].shift(3)\n",
    "    line_data['Rolling_3'] = line_data['Trips'].rolling(window=3).mean()\n",
    "    line_data = line_data.dropna()\n",
    "    \n",
    "    print(f\"   Training samples: {len(line_data)}\")\n",
    "    \n",
    "    if len(line_data) > 10:\n",
    "        features = ['Year', 'Month', 'Quarter', 'Lag_1', 'Lag_3', 'Rolling_3']\n",
    "        X = line_data[features]\n",
    "        y = line_data['Trips']\n",
    "        \n",
    "        split_idx = int(len(line_data) * 0.8)\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        print(f\"   Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "        \n",
    "        print(\"\\nðŸ¤– Training Random Forest...\")\n",
    "        model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "        \n",
    "        print(\"\\nðŸ“Š MODEL PERFORMANCE:\\n\")\n",
    "        print(f\"   Line: {target_line}\")\n",
    "        print(f\"   RMSE: {rmse:,.0f} trips\")\n",
    "        print(f\"   MAE:  {mae:,.0f} trips\")\n",
    "        print(f\"   RÂ²:   {r2:.4f}\")\n",
    "        print(f\"   MAPE: {mape:.2f}%\")\n",
    "        \n",
    "        print(\"\\nðŸ”® PREDICTIONS (Last 5 test periods):\\n\")\n",
    "        for i in range(min(5, len(y_test))):\n",
    "            idx = -5 + i\n",
    "            actual = y_test.values[idx]\n",
    "            predicted = y_pred[idx]\n",
    "            error_pct = ((actual - predicted) / actual) * 100\n",
    "            print(f\"   Actual: {actual:>10,.0f} | Predicted: {predicted:>10,.0f} | Error: {error_pct:+6.1f}%\")\n",
    "        \n",
    "    else:\n",
    "        print(\"   âš ï¸  Insufficient data for this line\")\n",
    "else:\n",
    "    print(\"âš ï¸  Not enough data for ML training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question 3: Which stations need capacity upgrades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "â“ QUESTION 3: WHICH STATIONS/LINES NEED CAPACITY UPGRADES?\n",
      "================================================================================\n",
      "\n",
      "âš ï¸  CAPACITY ANALYSIS (Threshold: 1,500,000 trips/month)\n",
      "\n",
      "Status: ðŸ”´ >90% | ðŸŸ¡ 75-90% | ðŸŸ¢ <75%\n",
      "\n",
      "ðŸŸ¢ OK         T2 Inner West & Leppington Line                 23.0% | Avg:    345,454\n",
      "ðŸŸ¢ OK         T1 North Shore Line & T1 Western Line           10.0% | Avg:    149,799\n",
      "ðŸŸ¢ OK         T9 Northern Line                                 5.9% | Avg:     88,155\n",
      "ðŸŸ¢ OK         T8 Airport & South Line                          5.9% | Avg:     88,124\n",
      "ðŸŸ¢ OK         T3 Bankstown Line                                4.0% | Avg:     59,520\n",
      "ðŸŸ¢ OK         Central Coast & Newcastle Line                   2.3% | Avg:     34,364\n",
      "ðŸŸ¢ OK         T4 Eastern Suburbs & Illawarra Line              2.2% | Avg:     32,700\n",
      "ðŸŸ¢ OK         T2 Inner West & Leppington Line & T2 Leppingt    2.1% | Avg:     31,809\n",
      "ðŸŸ¢ OK         T3 Bankstown Line & T3 Liverpool & Inner West    1.4% | Avg:     21,719\n",
      "ðŸŸ¢ OK         South Coast Line                                 1.1% | Avg:     15,962\n",
      "ðŸŸ¢ OK         T5 Cumberland Line                               1.0% | Avg:     15,746\n",
      "ðŸŸ¢ OK         Blue Mountains Line                              0.9% | Avg:     14,144\n",
      "ðŸŸ¢ OK         T6 Lidcombe & Bankstown Line                     0.6% | Avg:      9,590\n",
      "ðŸŸ¢ OK         Hunter Line                                      0.2% | Avg:      2,546\n",
      "ðŸŸ¢ OK         Southern Highlands Line                          0.2% | Avg:      2,424\n",
      "\n",
      "ðŸ’¼ INVESTMENT RECOMMENDATIONS:\n",
      "\n",
      "   âœ… All lines operating within safe capacity limits\n"
     ]
    }
   ],
   "source": [
    "if df_clean is not None and len(df_clean) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"â“ QUESTION 3: WHICH STATIONS/LINES NEED CAPACITY UPGRADES?\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calculate recent average (last 6 months)\n",
    "    recent_data = df_clean.sort_values('Date').groupby('Line').tail(6)\n",
    "    \n",
    "    capacity_analysis = []\n",
    "    CAPACITY_THRESHOLD = 1_500_000  # Assume 1.5M trips/month as capacity\n",
    "    \n",
    "    for line in df_clean['Line'].unique():\n",
    "        line_recent = recent_data[recent_data['Line'] == line]\n",
    "        \n",
    "        if len(line_recent) > 0:\n",
    "            avg_trips = line_recent['Trips'].mean()\n",
    "            max_trips = line_recent['Trips'].max()\n",
    "            capacity_used_pct = (avg_trips / CAPACITY_THRESHOLD) * 100\n",
    "            \n",
    "            capacity_analysis.append({\n",
    "                'Line': line,\n",
    "                'Avg_Monthly': avg_trips,\n",
    "                'Max_Monthly': max_trips,\n",
    "                'Capacity_Used': capacity_used_pct\n",
    "            })\n",
    "    \n",
    "    capacity_df = pd.DataFrame(capacity_analysis).sort_values('Capacity_Used', ascending=False)\n",
    "    \n",
    "    print(f\"\\nâš ï¸  CAPACITY ANALYSIS (Threshold: {CAPACITY_THRESHOLD:,} trips/month)\\n\")\n",
    "    print(\"Status: ðŸ”´ >90% | ðŸŸ¡ 75-90% | ðŸŸ¢ <75%\\n\")\n",
    "    \n",
    "    critical_count = 0\n",
    "    warning_count = 0\n",
    "    \n",
    "    for idx, row in capacity_df.head(15).iterrows():\n",
    "        if row['Capacity_Used'] > 90:\n",
    "            status = \"ðŸ”´ CRITICAL\"\n",
    "            critical_count += 1\n",
    "        elif row['Capacity_Used'] > 75:\n",
    "            status = \"ðŸŸ¡ WARNING\"\n",
    "            warning_count += 1\n",
    "        else:\n",
    "            status = \"ðŸŸ¢ OK\"\n",
    "        \n",
    "        print(f\"{status:12} {row['Line'][:45]:45} {row['Capacity_Used']:6.1f}% | Avg: {row['Avg_Monthly']:>10,.0f}\")\n",
    "    \n",
    "    print(\"\\nðŸ’¼ INVESTMENT RECOMMENDATIONS:\\n\")\n",
    "    \n",
    "    if critical_count > 0:\n",
    "        total_investment = critical_count * 50_000_000\n",
    "        print(f\"   ðŸš¨ URGENT: {critical_count} lines need immediate capacity expansion\")\n",
    "        print(f\"   ðŸ’° Estimated investment: ${total_investment:,}\")\n",
    "        print(f\"   ðŸ“Š Actions:\")\n",
    "        print(f\"      - Add rolling stock (trains)\")\n",
    "        print(f\"      - Increase service frequency\")\n",
    "        print(f\"      - Upgrade signaling for closer headways\")\n",
    "    \n",
    "    if warning_count > 0:\n",
    "        print(f\"\\n   âš ï¸  MONITOR: {warning_count} lines approaching capacity\")\n",
    "        print(f\"   ðŸ“Š Plan upgrades for next 2-3 years\")\n",
    "    \n",
    "    if critical_count == 0 and warning_count == 0:\n",
    "        print(\"   âœ… All lines operating within safe capacity limits\")\n",
    "else:\n",
    "    print(\"âš ï¸  No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question 4: Optimal train frequency per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "â“ QUESTION 4: OPTIMAL TRAIN FREQUENCY PER LINE\n",
      "================================================================================\n",
      "\n",
      "ðŸš‚ FREQUENCY RECOMMENDATIONS (Based on last 6 months):\n",
      "\n",
      "Formula: Daily trips Ã· Train capacity (1,000 passengers) Ã· Operating hours\n",
      "\n",
      "  T2 Inner West & Leppington Line               |   0.6/hr | Every 30+ min (Low frequency)\n",
      "  T1 North Shore Line & T1 Western Line         |   0.3/hr | Every 30+ min (Low frequency)\n",
      "  T9 Northern Line                              |   0.2/hr | Every 30+ min (Low frequency)\n",
      "  T8 Airport & South Line                       |   0.2/hr | Every 30+ min (Low frequency)\n",
      "  T3 Bankstown Line                             |   0.1/hr | Every 30+ min (Low frequency)\n",
      "  Central Coast & Newcastle Line                |   0.1/hr | Every 30+ min (Low frequency)\n",
      "  T4 Eastern Suburbs & Illawarra Line           |   0.1/hr | Every 30+ min (Low frequency)\n",
      "  T2 Inner West & Leppington Line & T2 Leppingt |   0.1/hr | Every 30+ min (Low frequency)\n",
      "  T3 Bankstown Line & T3 Liverpool & Inner West |   0.0/hr | Every 30+ min (Low frequency)\n",
      "  South Coast Line                              |   0.0/hr | Every 30+ min (Low frequency)\n",
      "  T5 Cumberland Line                            |   0.0/hr | Every 30+ min (Low frequency)\n",
      "  Blue Mountains Line                           |   0.0/hr | Every 30+ min (Low frequency)\n",
      "  T6 Lidcombe & Bankstown Line                  |   0.0/hr | Every 30+ min (Low frequency)\n",
      "  Hunter Line                                   |   0.0/hr | Every 30+ min (Low frequency)\n",
      "  Southern Highlands Line                       |   0.0/hr | Every 30+ min (Low frequency)\n",
      "\n",
      "ðŸ’¼ OPERATIONAL RECOMMENDATIONS:\n",
      "\n",
      "\n",
      "   ðŸšƒ 25 lines can operate with lower frequency (>30 min)\n",
      "   ðŸ’° Potential savings: $50,000,000/year\n"
     ]
    }
   ],
   "source": [
    "if df_clean is not None and len(df_clean) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"â“ QUESTION 4: OPTIMAL TRAIN FREQUENCY PER LINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    recent_data = df_clean.sort_values('Date').groupby('Line').tail(6)\n",
    "    \n",
    "    print(\"\\nðŸš‚ FREQUENCY RECOMMENDATIONS (Based on last 6 months):\\n\")\n",
    "    print(\"Formula: Daily trips Ã· Train capacity (1,000 passengers) Ã· Operating hours\\n\")\n",
    "    \n",
    "    frequency_recommendations = []\n",
    "    \n",
    "    for line in df_clean['Line'].unique():\n",
    "        line_recent = recent_data[recent_data['Line'] == line]\n",
    "        \n",
    "        if len(line_recent) > 0:\n",
    "            avg_monthly = line_recent['Trips'].mean()\n",
    "            avg_daily = avg_monthly / 30\n",
    "            trains_needed_daily = avg_daily / 1000  # Capacity = 1000 passengers/train\n",
    "            operating_hours = 19  # 5am-12am\n",
    "            trains_per_hour = trains_needed_daily / operating_hours\n",
    "            minutes_between = 60 / trains_per_hour if trains_per_hour > 0 else 60\n",
    "            \n",
    "            frequency_recommendations.append({\n",
    "                'Line': line,\n",
    "                'Daily_Trips': avg_daily,\n",
    "                'Trains_Per_Hour': trains_per_hour,\n",
    "                'Minutes_Between': minutes_between\n",
    "            })\n",
    "    \n",
    "    freq_df = pd.DataFrame(frequency_recommendations).sort_values('Trains_Per_Hour', ascending=False)\n",
    "    \n",
    "    for idx, row in freq_df.head(15).iterrows():\n",
    "        if row['Minutes_Between'] <= 5:\n",
    "            rec = \"Every 3-5 min (Metro frequency)\"\n",
    "        elif row['Minutes_Between'] <= 10:\n",
    "            rec = \"Every 6-10 min (High frequency)\"\n",
    "        elif row['Minutes_Between'] <= 20:\n",
    "            rec = \"Every 15-20 min (Standard)\"\n",
    "        else:\n",
    "            rec = \"Every 30+ min (Low frequency)\"\n",
    "        \n",
    "        print(f\"  {row['Line'][:45]:45} | {row['Trains_Per_Hour']:5.1f}/hr | {rec}\")\n",
    "    \n",
    "    print(\"\\nðŸ’¼ OPERATIONAL RECOMMENDATIONS:\\n\")\n",
    "    \n",
    "    high_freq = freq_df[freq_df['Minutes_Between'] <= 10]\n",
    "    if len(high_freq) > 0:\n",
    "        print(f\"   ðŸš„ {len(high_freq)} lines require high-frequency service (â‰¤10 min)\")\n",
    "        print(f\"   ðŸ“Š Actions: Automated trains, dedicated staff, priority maintenance\")\n",
    "    \n",
    "    low_freq = freq_df[freq_df['Minutes_Between'] > 30]\n",
    "    if len(low_freq) > 0:\n",
    "        print(f\"\\n   ðŸšƒ {len(low_freq)} lines can operate with lower frequency (>30 min)\")\n",
    "        print(f\"   ðŸ’° Potential savings: ${len(low_freq) * 2_000_000:,}/year\")\n",
    "else:\n",
    "    print(\"âš ï¸  No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question 5: Card type usage patterns\n",
    "\n",
    "**Using dedicated card type API endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "â“ QUESTION 5: CARD TYPE USAGE PATTERNS\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ« Fetching card type data from dedicated API...\n",
      "\n",
      "âœ… SUCCESS! Retrieved 6342 records\n",
      "   Columns: ['_id', 'Year_Month', 'Card_type', 'Travel_Mode', 'Trip']\n",
      "\n",
      "ðŸ“Š CARD TYPE DATA STRUCTURE:\n",
      "\n",
      "Sample record:\n",
      "   _id Year_Month    Card_type Travel_Mode        Trip\n",
      "0    1   Jul-2016        Adult         Bus  13146432.0\n",
      "1    2   Jul-2016  Child/Youth         Bus   1079640.0\n",
      "2    3   Jul-2016   Concession         Bus   1845322.0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "   âš ï¸  No card type columns found in this dataset\n",
      "\n",
      "   ðŸ“Š Data Structure:\n",
      "      â€¢ _id: int64\n",
      "      â€¢ Year_Month: object\n",
      "      â€¢ Card_type: object\n",
      "      â€¢ Travel_Mode: object\n",
      "      â€¢ Trip: float64\n"
     ]
    }
   ],
   "source": [
    "def fetch_card_type_data():\n",
    "    \"\"\"\n",
    "    Fetch card type usage data from dedicated endpoint\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"â“ QUESTION 5: CARD TYPE USAGE PATTERNS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nðŸŽ« Fetching card type data from dedicated API...\\n\")\n",
    "    \n",
    "    url = \"https://opendata.transport.nsw.gov.au/data/api/action/datastore_search\"\n",
    "    params = {\n",
    "        'resource_id': 'c77b83d7-cdcd-4a0e-9b12-fcc159727589',\n",
    "        'limit': 100000\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=60)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'result' in data and 'records' in data['result']:\n",
    "                df_cards = pd.DataFrame(data['result']['records'])\n",
    "                \n",
    "                print(f\"âœ… SUCCESS! Retrieved {len(df_cards)} records\")\n",
    "                print(f\"   Columns: {list(df_cards.columns)}\\n\")\n",
    "                \n",
    "                return df_cards\n",
    "            else:\n",
    "                print(\"âŒ Unexpected API response format\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"âŒ API returned status: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "df_cards = fetch_card_type_data()\n",
    "\n",
    "if df_cards is not None and len(df_cards) > 0:\n",
    "    # Explore the data structure\n",
    "    print(\"ðŸ“Š CARD TYPE DATA STRUCTURE:\\n\")\n",
    "    print(\"Sample record:\")\n",
    "    print(df_cards.head(3))\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Identify card type columns\n",
    "    card_type_keywords = ['Adult', 'Child', 'Senior', 'Concession', 'School', 'Student']\n",
    "    card_cols = [col for col in df_cards.columns if any(card.lower() in col.lower() for card in card_type_keywords)]\n",
    "    \n",
    "    if len(card_cols) > 0:\n",
    "        print(f\"\\nðŸŽ« Found {len(card_cols)} card type columns:\\n\")\n",
    "        for col in card_cols:\n",
    "            print(f\"   â€¢ {col}\")\n",
    "        \n",
    "        # Calculate totals\n",
    "        card_totals = {}\n",
    "        for col in card_cols:\n",
    "            try:\n",
    "                # Convert to numeric and sum\n",
    "                total = pd.to_numeric(df_cards[col], errors='coerce').sum()\n",
    "                if total > 0:\n",
    "                    card_totals[col] = total\n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸  Could not process {col}: {str(e)}\")\n",
    "        \n",
    "        if card_totals:\n",
    "            total_all = sum(card_totals.values())\n",
    "            \n",
    "            print(\"\\nðŸ“Š CARD TYPE DISTRIBUTION:\\n\")\n",
    "            sorted_cards = sorted(card_totals.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for card, count in sorted_cards:\n",
    "                pct = (count / total_all) * 100\n",
    "                bar = 'â–ˆ' * int(pct / 2)\n",
    "                # Clean up card name\n",
    "                card_name = card.replace('_', ' ').title()\n",
    "                print(f\"  {card_name[:35]:35} {count:>15,.0f} trips ({pct:5.1f}%) {bar}\")\n",
    "            \n",
    "            print(f\"\\n  {'TOTAL':35} {total_all:>15,.0f} trips (100.0%)\")\n",
    "            \n",
    "            # Business insights\n",
    "            print(\"\\nðŸ’¼ BUSINESS INSIGHTS:\\n\")\n",
    "            \n",
    "            top_segment = sorted_cards[0]\n",
    "            top_name = top_segment[0].replace('_', ' ').title()\n",
    "            top_pct = (top_segment[1] / total_all) * 100\n",
    "            print(f\"   ðŸ’³ PRIMARY SEGMENT: {top_name}\")\n",
    "            print(f\"      - {top_pct:.1f}% of all trips\")\n",
    "            print(f\"      - {top_segment[1]:,.0f} total trips\")\n",
    "            \n",
    "            # Identify concession cards\n",
    "            concession_keywords = ['concession', 'senior', 'pension']\n",
    "            concession_cards = [c for c in sorted_cards if any(kw in c[0].lower() for kw in concession_keywords)]\n",
    "            \n",
    "            if concession_cards:\n",
    "                conc_total = sum(c[1] for c in concession_cards)\n",
    "                conc_pct = (conc_total / total_all) * 100\n",
    "                print(f\"\\n   ðŸ‘´ CONCESSION/SENIOR SEGMENT:\")\n",
    "                print(f\"      - {conc_pct:.1f}% of trips\")\n",
    "                print(f\"      - {conc_total:,.0f} total trips\")\n",
    "                if conc_pct < 20:\n",
    "                    print(f\"      - ðŸ’¡ GROWTH OPPORTUNITY: Increase seniors engagement\")\n",
    "                    print(f\"      - Actions: Better accessibility, off-peak discounts\")\n",
    "            \n",
    "            # Adult revenue analysis\n",
    "            adult_cards = [c for c in sorted_cards if 'adult' in c[0].lower()]\n",
    "            if adult_cards:\n",
    "                adult_total = sum(c[1] for c in adult_cards)\n",
    "                adult_pct = (adult_total / total_all) * 100\n",
    "                \n",
    "                if adult_pct > 50:\n",
    "                    print(f\"\\n   ðŸ’° REVENUE STRATEGY:\")\n",
    "                    print(f\"      - Adult cards: {adult_pct:.1f}% of trips\")\n",
    "                    print(f\"      - Primary revenue driver\")\n",
    "                    print(f\"      - Focus areas:\")\n",
    "                    print(f\"        â€¢ Peak-hour service reliability\")\n",
    "                    print(f\"        â€¢ Premium express services\")\n",
    "                    print(f\"        â€¢ Workplace partnership programs\")\n",
    "            \n",
    "            # Child/Student analysis\n",
    "            youth_keywords = ['child', 'student', 'school']\n",
    "            youth_cards = [c for c in sorted_cards if any(kw in c[0].lower() for kw in youth_keywords)]\n",
    "            \n",
    "            if youth_cards:\n",
    "                youth_total = sum(c[1] for c in youth_cards)\n",
    "                youth_pct = (youth_total / total_all) * 100\n",
    "                print(f\"\\n   ðŸŽ’ CHILD/STUDENT SEGMENT:\")\n",
    "                print(f\"      - {youth_pct:.1f}% of trips\")\n",
    "                print(f\"      - Peak during school terms\")\n",
    "                print(f\"      - Actions: School holiday service adjustments\")\n",
    "            \n",
    "            # ROI calculation\n",
    "            print(\"\\nðŸ’µ REVENUE OPTIMIZATION POTENTIAL:\\n\")\n",
    "            \n",
    "            # If adults are >60%, optimize for them\n",
    "            if adult_pct > 60:\n",
    "                print(f\"   ðŸ“Š SCENARIO: +5% Adult retention through improved service\")\n",
    "                print(f\"      Current adult trips: {adult_total:,.0f}\")\n",
    "                print(f\"      Additional trips: {adult_total * 0.05:,.0f}\")\n",
    "                print(f\"      Revenue increase: ${adult_total * 0.05 * 3.5:,.0f} (@$3.50/trip)\")\n",
    "            \n",
    "            # If concessions are <20%, there's growth opportunity\n",
    "            if concession_cards and conc_pct < 20:\n",
    "                print(f\"\\n   ðŸ“Š SCENARIO: +3% Concession growth through accessibility\")\n",
    "                print(f\"      Current concession trips: {conc_total:,.0f}\")\n",
    "                print(f\"      Additional trips: {conc_total * 0.03:,.0f}\")\n",
    "                print(f\"      Revenue increase: ${conc_total * 0.03 * 1.75:,.0f} (@$1.75/trip)\")\n",
    "            \n",
    "        else:\n",
    "            print(\"   âš ï¸  Could not calculate card type totals\")\n",
    "    else:\n",
    "        print(\"\\n   âš ï¸  No card type columns found in this dataset\")\n",
    "        print(\"\\n   ðŸ“Š Data Structure:\")\n",
    "        for col in df_cards.columns:\n",
    "            print(f\"      â€¢ {col}: {str(df_cards[col].dtype)}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Could not fetch card type data\")\n",
    "    print(\"   Check: Internet connection, API availability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Question 6: Seasonal Demand Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "â“ QUESTION 6: SEASONAL DEMAND PATTERNS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“… MONTHLY DEMAND PATTERN:\n",
      "\n",
      "           Jan       106,687 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Feb       120,458 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  ðŸ”´ PEAK   Mar       138,013 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Apr       119,660 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           May       131,684 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Jun       118,812 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Jul       125,205 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Aug       123,521 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Sep       132,572 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Oct       125,065 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "           Nov       113,873 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  ðŸ”µ LOW    Dec       105,195 trips â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ðŸ“Š SEASONALITY METRICS:\n",
      "\n",
      "   Peak Month: Mar - 138,013 trips\n",
      "   Low Month:  Dec - 105,195 trips\n",
      "   Variation:  31.2%\n",
      "\n",
      "ðŸ’¼ OPERATIONAL RECOMMENDATIONS:\n",
      "\n",
      "   ðŸš‚ PEAK PERIOD (Mar)\n",
      "      - Increase services by 16%\n",
      "      - All staff on duty\n",
      "      - Defer non-critical maintenance\n",
      "\n",
      "   ðŸ”§ LOW PERIOD (Dec)\n",
      "      - Reduce services by 10%\n",
      "      - Schedule major maintenance\n",
      "      - Staff training and leave\n",
      "      - Cost savings: $15,599,118/month\n",
      "\n",
      "   ðŸŒž Summer average: 110,780 trips/month\n",
      "   â„ï¸  Winter average: 122,512 trips/month\n",
      "   ðŸ“Š School holidays reduce patronage in summer\n"
     ]
    }
   ],
   "source": [
    "if df_clean is not None and len(df_clean) > 12:\n",
    "    print(\"=\"*80)\n",
    "    print(\"â“ QUESTION 6: SEASONAL DEMAND PATTERNS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if 'Month' in df_clean.columns:\n",
    "        monthly_avg = df_clean.groupby('Month')['Trips'].mean().sort_index()\n",
    "        \n",
    "        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                       'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        \n",
    "        seasonal_data = pd.DataFrame({\n",
    "            'Month': [month_names[i-1] for i in monthly_avg.index],\n",
    "            'Avg_Trips': monthly_avg.values\n",
    "        })\n",
    "        \n",
    "        peak_month = seasonal_data.loc[seasonal_data['Avg_Trips'].idxmax()]\n",
    "        low_month = seasonal_data.loc[seasonal_data['Avg_Trips'].idxmin()]\n",
    "        \n",
    "        print(\"\\nðŸ“… MONTHLY DEMAND PATTERN:\\n\")\n",
    "        \n",
    "        for idx, row in seasonal_data.iterrows():\n",
    "            pct_of_peak = (row['Avg_Trips'] / peak_month['Avg_Trips']) * 100\n",
    "            bar = 'â–ˆ' * int(pct_of_peak / 5)\n",
    "            \n",
    "            if row['Month'] == peak_month['Month']:\n",
    "                marker = 'ðŸ”´ PEAK'\n",
    "            elif row['Month'] == low_month['Month']:\n",
    "                marker = 'ðŸ”µ LOW'\n",
    "            else:\n",
    "                marker = '  '\n",
    "            \n",
    "            print(f\"  {marker:8} {row['Month']:4} {row['Avg_Trips']:>12,.0f} trips {bar}\")\n",
    "        \n",
    "        variation_pct = ((peak_month['Avg_Trips'] - low_month['Avg_Trips']) / low_month['Avg_Trips']) * 100\n",
    "        \n",
    "        print(f\"\\nðŸ“Š SEASONALITY METRICS:\\n\")\n",
    "        print(f\"   Peak Month: {peak_month['Month']} - {peak_month['Avg_Trips']:,.0f} trips\")\n",
    "        print(f\"   Low Month:  {low_month['Month']} - {low_month['Avg_Trips']:,.0f} trips\")\n",
    "        print(f\"   Variation:  {variation_pct:.1f}%\")\n",
    "        \n",
    "        print(\"\\nðŸ’¼ OPERATIONAL RECOMMENDATIONS:\\n\")\n",
    "        \n",
    "        print(f\"   ðŸš‚ PEAK PERIOD ({peak_month['Month']})\")\n",
    "        print(f\"      - Increase services by {variation_pct/2:.0f}%\")\n",
    "        print(f\"      - All staff on duty\")\n",
    "        print(f\"      - Defer non-critical maintenance\")\n",
    "        \n",
    "        print(f\"\\n   ðŸ”§ LOW PERIOD ({low_month['Month']})\")\n",
    "        print(f\"      - Reduce services by {variation_pct/3:.0f}%\")\n",
    "        print(f\"      - Schedule major maintenance\")\n",
    "        print(f\"      - Staff training and leave\")\n",
    "        print(f\"      - Cost savings: ${variation_pct * 500000:,.0f}/month\")\n",
    "        \n",
    "        summer_months = [12, 1, 2]\n",
    "        winter_months = [6, 7, 8]\n",
    "        \n",
    "        summer_avg = seasonal_data[seasonal_data.index.isin([i-1 for i in summer_months if i <= 12])]['Avg_Trips'].mean()\n",
    "        winter_avg = seasonal_data[seasonal_data.index.isin([i-1 for i in winter_months])]['Avg_Trips'].mean()\n",
    "        \n",
    "        print(f\"\\n   ðŸŒž Summer average: {summer_avg:,.0f} trips/month\")\n",
    "        print(f\"   â„ï¸  Winter average: {winter_avg:,.0f} trips/month\")\n",
    "        \n",
    "        if summer_avg < winter_avg:\n",
    "            print(f\"   ðŸ“Š School holidays reduce patronage in summer\")\n",
    "        else:\n",
    "            print(f\"   ðŸ“Š Tourist activity increases summer patronage\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  Month column not available\")\n",
    "else:\n",
    "    print(\"âš ï¸  Need at least 12 months of data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
